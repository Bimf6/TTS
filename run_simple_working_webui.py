#!/usr/bin/env python3
"""
Simple Working Fish Speech TTS WebUI
Focus on basic functionality that actually works
"""

import os
import gradio as gr
import torch
import numpy as np
import tempfile
import uuid
from pathlib import Path
from loguru import logger
import pyrootutils
import queue
import threading
from dataclasses import dataclass
from typing import Optional

# Setup the root path
pyrootutils.setup_root(__file__, indicator=".project-root", pythonpath=True)

from fish_speech.models.text2semantic.inference import (
    launch_thread_safe_queue,
    GenerateRequest,
    WrappedGenerateResponse,
)

# Make einx happy
os.environ["EINX_FILTER_TRACEBACK"] = "false"

# Language configurations
LANGUAGES = {
    "auto": "ğŸŒ Auto-detect",
    "en": "ğŸ‡ºğŸ‡¸ English", 
    "zh": "ğŸ‡¨ğŸ‡³ Mandarin Chinese",
    "ja": "ğŸ‡¯ğŸ‡µ Japanese",
    "ko": "ğŸ‡°ğŸ‡· Korean",
    "fr": "ğŸ‡«ğŸ‡· French",
    "de": "ğŸ‡©ğŸ‡ª German",
    "es": "ğŸ‡ªğŸ‡¸ Spanish",
}

def initialize_model():
    """Initialize the text-to-semantic model"""
    # Auto-detect device
    if torch.backends.mps.is_available():
        device = "mps"
        logger.info("MPS is available, running on MPS.")
    elif torch.cuda.is_available():
        device = "cuda"
        logger.info("CUDA is available, running on CUDA.")
    else:
        device = "cpu"
        logger.info("No GPU detected, running on CPU.")
    
    checkpoint_path = "checkpoints/fish-speech-1.5"
    
    # Check if model exists
    if not Path(checkpoint_path).exists():
        logger.error(f"Model checkpoint not found at {checkpoint_path}")
        return None, device
        
    logger.info("Model checkpoint found successfully!")
    
    # Initialize the thread-safe queue for inference
    try:
        model_queue = launch_thread_safe_queue(
            checkpoint_path=checkpoint_path,
            device=device,
            precision=torch.half if device != "cpu" else torch.float32,
            compile=False,
        )
        logger.info("Model loaded successfully!")
        return model_queue, device
    except Exception as e:
        logger.error(f"Failed to load model: {e}")
        return None, device

# Global model queue
model_queue = None
device = None

def get_language_code(language_display):
    """Convert display language to code"""
    for code, display in LANGUAGES.items():
        if display == language_display:
            return code
    return "auto"

def generate_speech(
    text, 
    language="ğŸŒ Auto-detect",
    max_tokens=512,
    temperature=0.7,
    top_p=0.7,
    repetition_penalty=1.5
):
    """Generate speech from text using the simplest approach"""
    global model_queue, device
    
    if not model_queue:
        return None, "âŒ Model not loaded. Please restart the application."
    
    if not text.strip():
        return None, "âŒ Please enter some text to generate speech."
    
    try:
        # Get language code
        lang_code = get_language_code(language)
        logger.info(f"Generating speech for: {text[:50]}... (Language: {lang_code})")
        
        logger.info("Starting semantic token generation...")
        
        # Create the generation request with ONLY supported parameters
        request_data = {
            "text": text,
            "device": device,  # Required parameter
            "max_new_tokens": max_tokens,
            "top_p": top_p,
            "repetition_penalty": repetition_penalty,
            "temperature": temperature,
            "chunk_length": 200,
            "num_samples": 1,
            "iterative_prompt": True,
        }
        
        # Create response queue
        response_queue = queue.Queue()
        
        # Create and send request
        generate_request = GenerateRequest(
            request=request_data,
            response_queue=response_queue
        )
        
        # Send request to model queue
        model_queue.put(generate_request)
        
        # Collect all responses
        all_tokens = []
        
        while True:
            try:
                response: WrappedGenerateResponse = response_queue.get(timeout=60)
                if response.status == "success":
                    if response.response is not None:
                        all_tokens.extend(response.response)
                    else:
                        # End of generation
                        break
                else:
                    logger.error(f"Generation error: {response.response}")
                    return None, f"âŒ Generation failed: {response.response}"
            except queue.Empty:
                logger.error("Generation timed out")
                return None, "âŒ Generation timed out after 60 seconds. Please try again with shorter text."
        
        if not all_tokens:
            return None, "âŒ No semantic tokens generated. Please try again."
        
        # Convert tokens to numpy array and save
        semantic_tokens = np.array(all_tokens, dtype=np.int32)
        
        # Create temporary file to save semantic tokens
        temp_dir = Path("temp")
        temp_dir.mkdir(exist_ok=True)
        
        output_file = temp_dir / f"speech_tokens_{uuid.uuid4().hex[:8]}.npy"
        np.save(output_file, semantic_tokens)
        
        logger.info(f"âœ… Generated {len(semantic_tokens)} semantic tokens")
        logger.info(f"Saved semantic tokens to: {output_file}")
        
        success_message = f"""âœ… Speech generation successful!

ğŸ“Š Generated: {len(semantic_tokens)} semantic tokens
ğŸŒ Language: {language}
ğŸ“ Text: {text[:100]}{'...' if len(text) > 100 else ''}

ğŸ“ File saved: {output_file.name}

ğŸµ Your speech has been converted to semantic tokens which represent the AI's understanding of how your text should sound. These tokens can be processed further to create actual audio files."""
        
        return str(output_file), success_message
        
    except Exception as e:
        logger.error(f"Speech generation failed: {e}")
        return None, f"âŒ Speech generation failed: {str(e)}"

def create_simple_webui():
    """Create a simple, working TTS WebUI interface"""
    
    with gr.Blocks(
        title="ğŸ  Fish Speech - Simple TTS",
        theme=gr.themes.Soft(),
        css="""
        .main-header { text-align: center; margin-bottom: 2rem; }
        .status-box { background-color: #f8f9fa; border: 1px solid #dee2e6; border-radius: 8px; padding: 1rem; }
        """
    ) as app:
        
        # Header
        gr.HTML("""
        <div class="main-header">
            <h1>ğŸ  Fish Speech - Simple TTS</h1>
            <p>Simple and reliable text-to-speech generation</p>
        </div>
        """)
        
        with gr.Row():
            with gr.Column(scale=2):
                # Text input
                text_input = gr.Textbox(
                    label="ğŸ“ Enter Your Text",
                    placeholder="Type your text here... (English, ä¸­æ–‡, æ—¥æœ¬èª, í•œêµ­ì–´, etc.)",
                    lines=5,
                    max_lines=15
                )
                
                # Language selection
                language_dropdown = gr.Dropdown(
                    choices=list(LANGUAGES.values()),
                    value="ğŸŒ Auto-detect",
                    label="ğŸŒ Language"
                )
                
                # Simple settings
                with gr.Accordion("âš™ï¸ Settings", open=False):
                    with gr.Row():
                        max_tokens = gr.Slider(
                            minimum=64,
                            maximum=1024,
                            value=512,
                            step=64,
                            label="Max Tokens"
                        )
                        temperature = gr.Slider(
                            minimum=0.1,
                            maximum=1.5,
                            value=0.7,
                            step=0.1,
                            label="Temperature (Creativity)"
                        )
                    with gr.Row():
                        top_p = gr.Slider(
                            minimum=0.1,
                            maximum=1.0,
                            value=0.7,
                            step=0.05,
                            label="Top P (Diversity)"
                        )
                        repetition_penalty = gr.Slider(
                            minimum=1.0,
                            maximum=2.0,
                            value=1.5,
                            step=0.1,
                            label="Repetition Penalty"
                        )
            
            with gr.Column(scale=1):
                # Generate button
                generate_btn = gr.Button(
                    "ğŸµ Generate Speech",
                    variant="primary",
                    size="lg"
                )
                
                # Output
                output_file = gr.File(
                    label="ğŸ“ Generated Speech Tokens",
                    file_count="single"
                )
                
                status_output = gr.Textbox(
                    label="ğŸ“Š Status",
                    lines=12,
                    interactive=False
                )
        
        # Examples
        with gr.Row():
            gr.Examples(
                examples=[
                    ["Hello world! This is a test of Fish Speech.", "ğŸ‡ºğŸ‡¸ English"],
                    ["ä½ å¥½ä¸–ç•Œï¼è¿™æ˜¯Fish Speechçš„æµ‹è¯•ã€‚", "ğŸ‡¨ğŸ‡³ Mandarin Chinese"],
                    ["ã“ã‚“ã«ã¡ã¯ä¸–ç•Œï¼ã“ã‚Œã¯Fish Speechã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚", "ğŸ‡¯ğŸ‡µ Japanese"],
                    ["ì•ˆë…•í•˜ì„¸ìš”! Fish Speech í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.", "ğŸ‡°ğŸ‡· Korean"],
                    ["Bonjour le monde! Ceci est un test de Fish Speech.", "ğŸ‡«ğŸ‡· French"],
                ],
                inputs=[text_input, language_dropdown],
                label="ğŸ’¡ Try These Examples"
            )
        
        # Generate button click
        generate_btn.click(
            generate_speech,
            inputs=[
                text_input,
                language_dropdown,
                max_tokens,
                temperature,
                top_p,
                repetition_penalty
            ],
            outputs=[output_file, status_output]
        )
        
        # Footer
        gr.HTML("""
        <div style="text-align: center; margin-top: 2rem; padding: 1rem; border-top: 1px solid #e0e0e0;">
            <p>ğŸ  <strong>Fish Speech - Simple TTS</strong></p>
            <p>Converts text to semantic tokens that represent speech patterns</p>
        </div>
        """)
    
    return app

def main():
    """Main function to initialize and launch the WebUI"""
    global model_queue, device
    
    logger.info("Initializing Simple Fish Speech TTS WebUI...")
    
    # Initialize model
    model_queue, device = initialize_model()
    
    if not model_queue:
        logger.error("Failed to initialize model. Please check your setup.")
        return
    
    logger.info("Creating Simple TTS WebUI...")
    app = create_simple_webui()
    
    logger.info("Starting Simple TTS WebUI server...")
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True,
        debug=False
    )

if __name__ == "__main__":
    main()
